---
layout: post
title: A Survey - Marketing Research and Computer Vision, Part I
date: 2019-01-28
---


Image Processing or Computer Vision in Quantitative Marketing

A.K.A. Quantitative marketing research papers that have used image processing or computer vision methods

By no means exhaustive, non-judging.

<h4>Product Design</h4>

Dzyabura, Ibragimov and Kihal (2018) use machine learning models to predict demand in online and offline retail channels, as well as returns for new products. They measure sale distributions across channels for each product category and find those predominantly sold online are more prone to customer returns. They also demonstrate the superior prediction performance when product image features — color histograms, texture, learned representa- tion by training AlexNet (Krizhevsky, Sutskever and Hinton 2012) — are included.

Zhang, Lee, Singh and Srinivasan (2018) estimate the economic impact of images and low-level image features that property demand in Airbnb. By classifying property photos with computer vision and deep learning models, they show that 48.9% of the effect of verified images boosting demand comes from the high image quality. They also identify 12 image at- tributes based on marketing and photography literature and demonstrate the direct impacts of these on demand after controlling for many obserables, thus prescribing optimal product image strategies to increase demand for housing and lodging managers.

Tkachenko, Ansari and Toubia (2018) apply deep learning techniques for the purpose of computer-aided exploration of visual product designs, where alternative design methods, such as conjoint or brute-force search, may not be applicable or may perform suboptimally. In this work, they first confirm properties of the lower-dimensional latent space that are desirable — they show (a) how distance between images in this latent space mimics human similarity judgments about the actual images, and (b) that important characteristics of interest, such as product prices, can be predicted from latent image data alone. Building on these findings, they propose and demonstrate machine learning techniques for exploration and ideation in the design space, such as image interpolation to generate product designs that are similar to competitors products, or constrained Bayesian optimization to find novel designs that score high on quantitative characteristics of interest. They use images and attributes of products sold on Amazon.com as well as human feedback from Amazon Turk workers as a basis for experiments. Their results imply that deep generative models offer a promising avenue for partial automation of the visual product design process. This is perhaps the first study in marketing that has leveraged the GANs that have been all the rage in the machine learning community. To its core, it is an application of generative models and visual embeddings to the domain of product design. Without any new dataset, or new theories as the backbone, it would appear to be but another application of the aforementioned methods, since similar studies in computer vision (and natural language processing) abound. We review relevant computer vision literature in Part II.

Chan, Mihm and Sosa (2017) look into the ebbs and flows of styles in product design and how it relates to the evolution of product functionality over time, based on a large- scale US design patent dataset. They identify the styles in design using clustering and provide empirical evidence for the long-lived architectural and design mantra “Form follows function”.


<h4> Branding, and Visual User-Generated Content </h4>

Liu and Mayzlin (2018) propose a “visual listening in” approach to measuring how brands are portrayed on social media (Instagram) by mining visual content posted by users. They use supervised machine learning methods, traditional support vector machine classifiers and deep convolutional neural networks, to measure brand attributes (glamorous, rugged, healthy, fun) from images. Then they apply the classifiers to brand-related images posted on social media to measure what consumers are visually communicating about brands. By comparing the portrayals of 56 brands in the apparel and beverages categories in consumer-created images with images on the firms official Instagram account, as well as with consumer brand perceptions measured in a national brand survey, they find, despite convergent validity shown in all three measures, key differences between how consumers and firms portray the brands on visual social media, and how the average consumer perceives the brands.

Dew, Ansari and Toubia (2018) explore the visual elements in logos that express brand personality traits, based on which they introduce a logo tokenization algorithm that de- composes logos into theory-base and human-meaningful visual features. Applied to a small dataset of logos, matched with textual data from firms’ websites, consumer evaluations of brands, third-party descriptions of the companies, they uncover uncovers links that exist between a brands logo, description, and personality, and thereby facilitate a better under- standing of the underpinnings of good design, and inform the design of new logos.

Photos posted on social media often include people using specific brands of products. Online retailers sometimes display the photos on their sites hoping for positive brand image and observational learning. However sometimes, it is the person in the photo, rather than the brand, that attracts the visitors’ attention. Papatla (2018) investigates whether the presence of faces in VUGC could be less detrimental if they are less prominent, based on findings that faces and bodies of humans in the visual field are processed holistically even if they are seen as distinct stimuli. They analyze consumer response to about 12,000 photos of 800 different products in six categories displayed by 35 online retailers.

<h4> Fashion and Beauty </h4>
Shi, Lee, Singh and Srinivasan (2018) study the substitutability between the brand value and the style value in the fashion market. They quantify the style value by employing deep learning based computer vision techniques to create style features, including clothing style (e.g., compatibility between clothing items, creativity), model style (e.g., facial and body attractiveness), and photo style. These style features are incorporated in a dynamic structural model to estimate a dynamic structural model to analyze the content creation and consumption behavior of influencers in a fashion social network community. They find significant effects of brands and style features on the trendiness of a fashion look, as well as substitutability patterns between style features and brand levels. For managers and influencers in the fashion market, their results provide guidelines on how to engineer a fashion “look” that can attract the most attention. This is a nice addition to the economic paradigm of feature substitutability analyses, bolstered by computer vision methods.

Malik, Singh, Lee and Srinivasan (2018) investigate the the dynamic effects of beauty over an individuals career. They use computer vision methods to score the attractiveness of each individual in a longitudinal sample on career milestones, with which they estimate a survival analysis where attractive men are found to progress faster in their career early on and women are found to progress faster in their later career in comparison to their unattractive counterparts respectively. In other words, they find that men enjoy a beauty premium early in their career which disappears later in the career, whereas the opposite goes for women, even though the overall beauty premium is greater for women.

Todorov (2018) model social perception of faces using data-driven approaches whose objective is to identify quantitative relationships between high-dimensional variables (e.g., visual images) and behaviors (e.g., perceptual decisions) with as little bias as possible. They conduct a series of studies using reverse correlation methods based on judgments of randomly generated faces from a statistical, multidimensional face model; a vector space where every face can be represented as a vector in the space. These methods are used to a) model evaluation of faces on any social dimension (e.g., trustworthiness), and b) to identify the perceptual basis of this evaluation, thus mapping configurations of face features to specific social inferences.

<h4> Advertising </h4>

Xiao and Ding (2014) study the effect of non-celebrity faces in print advertising with es- tablished face recognition methods from computer vision. Specifically, they propose the use of eigenface features to segment people based on their preferences towards different faces. Siginificant and substantial effects of faces on viewers’ attitudes towards the ad, the brand, and their purchase intentions were documented. Considerable consistency is identified within subject, whereas substantial heterogeneity exists between subjects and among product cat- egories: certain eigenfaces are more predictive of greater viewer affinity for certain product categories. They also find that the effect of faces interacts with product categories and is mediated by various facial traits such as attractiveness, trustworthiness, and competence.

<h4> Applications of Face Recognition </h4>

Lu, Xiao and Ding (2016) claim to have developed one of the first attempts to integrate video analysis — real time facial expression recognition and hand detection — at the individual customer level with extant marketing research methods to create useful managerial tools in retail. They created an automatic and scalable garment recommender system that:
1. uses a camera to capture a shopper’s behavior in front of the mirror to make inferences about her preferences based on recognized facial expressions and region of interest (clothing being tried on);
2. matches the customer with a database of individuals with known fashion tastes and preferences, within which those with similar tastes are identified as nearest neighbors;
3. makes fashion recommendations to the focal customer based on preferences of identified individuals in the database.

Zhou, Lu and Ding (2016) propose a computer vision based framework to anonymize and distinguish facial images in online dating, which they, supposedly innocent non-English- speakers, termed as a FAP paradigm — a face anonymity-perceptibility framework that brings together face anonymity research from computer vision literature, and the percepti- bility studies from the social and the neuropsychology literature for marketing applications such as online dating, hiring, sales, and security. They select a set of facial landmarks for local or global facial features depending on the abstraction method used to anonymize. Then they show users abbreviated profiles including facial abstractions that preserve anonymity and perceptibility at the same time for preference estimation. Finally, a smaller set of potential partners are selected for the user to the best of his or her liking.

<h4> References (All Parts Combined) </h4>

Agarwal, Sameer, Noah Snavely, Ian Simon, Steven M Seitz, and Richard Szeliski, “Building rome in a day,” in “Computer Vision, 2009 IEEE 12th Interna- tional Conference on” IEEE 2009, pp. 72–79.
Azimi, Javad, Ruofei Zhang, Yang Zhou, Vidhya Navalpakkam, Jianchang Mao, and Xiaoli Fern, “Visual appearance of display ads and its effect on click through rate,” in “Proceedings of the 21st ACM international conference on Information and knowledge management” ACM 2012, pp. 495–504.
Berg, Thomas, Jiongxin Liu, Seung Woo Lee, Michelle L Alexander, David W Jacobs, and Peter N Belhumeur, “Birdsnap: Large-scale fine-grained visual cate- gorization of birds,” in “Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition” 2014, pp. 2011–2018.
Bossard, Lukas, Matthias Dantone, Christian Leistner, Christian Wengert, Till Quack, and Luc Van Gool, “Apparel classification with style,” in “Asian conference on computer vision” Springer 2012, pp. 321–335.
Bylinskii, Zoya, Nam Wook Kim, Peter O Donovan, Sami Alsheikh, Spandan Madan, Hanspeter Pfister, Fredo Durand, Bryan Russell, and Aaron Hertz- mann, “Learning Visual Importance for Graphic Designs and Data Visualizations,” in “Proceedings of the 30th Annual ACM Symposium on User Interface Software & Technology” 2017.
, Sami Alsheikh, Spandan Madan, Adria Recasens, Kimberli Zhong, Hanspeter Pfister, Fredo Durand, and Aude Oliva, “Understanding infographics through textual and visual tag prediction,” arXiv preprint arXiv:1709.09215, 2017.
Chan, Tian Heong, Ju ̈rgen Mihm, and Manuel E Sosa, “On Styles in Product Design: An Analysis of US Design Patents,” Management Science, 2017, 64 (3), 1230–1249.
Chandrasekaran, Arjun, Ashwin K Vijayakumar, Stanislaw Antol, Mohit Bansal, Dhruv Batra, C Lawrence Zitnick, and Devi Parikh, “We are humor beings: Understanding and predicting visual humor,” in “Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition” 2016, pp. 4603–4612.
Chao, Xiaofei, Mark J Huiskes, Tommaso Gritti, and Calina Ciuhu, “A framework for robust feature selection for real-time fashion style recommendation,” in “Proceedings of the 1st international workshop on Interactive multimedia for consumer electronics” ACM 2009, pp. 35–42.
Chen, Hong, Zi Jian Xu, Zi Qiang Liu, and Song Chun Zhu, “Composite Templates for Cloth Modeling and Sketching,” in “Computer Vision and Pattern Recognition (CVPR), 2006 IEEE Conference on” IEEE 2006.
Cheng, Haibin, Roelof van Zwol, Javad Azimi, Eren Manavoglu, Ruofei Zhang, Yang Zhou, and Vidhya Navalpakkam, “Multimedia features for click prediction of new ads in display advertising,” in “Proceedings of the 18th ACM SIGKDD interna- tional conference on Knowledge discovery and data mining” ACM 2012, pp. 777–785.
Chilton, Lydia B, “Constructing Visual Metaphors for Creative Ads,” 2018.
, James A Landay, and Daniel S Weld, “HumorTools: A Microtask Workflow for
Writing News Satire,” 2018.
Dew, Ryan, Asim Ansari, and Olivier Toubia, “Letting Logos Speak: A Machine Learning Approach for Data-Driven Logo Design,” 2018.
Doersch, Carl, Saurabh Singh, Abhinav Gupta, Josef Sivic, and Alexei A. Efros, “What Makes Paris Look like Paris?,” ACM Transactions on Graphics (SIGGRAPH), 2012, 31 (4), 101:1–101:9.
Dzyabura, Daria, Marat Ibragimov, and Siham El Kihal, 2018.
Eliashberg, Jehoshua, Anita Elberse, and Mark AAM Leenders, “The motion pic- ture industry: Critical issues in practice, current research, and new research directions,” Marketing science, 2006, 25 (6), 638–661.
Fleischman, Michael and Eduard Hovy, “Fine grained classification of named enti- ties,” in “Proceedings of the 19th international conference on Computational linguistics- Volume 1” Association for Computational Linguistics 2002, pp. 1–7.
Frahm, Jan-Michael, Pierre Fite-Georgel, David Gallup, Tim Johnson, Rahul Raguram, Changchang Wu, Yi-Hung Jen, Enrique Dunn, Brian Clipp, Svet- lana Lazebnik et al., “Building rome on a cloudless day,” in “European Conference on Computer Vision” Springer 2010, pp. 368–381.
Frome, Andrea, Greg S Corrado, Jon Shlens, Samy Bengio, Jeff Dean, Tomas Mikolov et al., “Devise: A deep visual-semantic embedding model,” in “Advances in neural information processing systems” 2013, pp. 2121–2129.
Garces, Elena, Aseem Agarwala, Diego Gutierrez, and Aaron Hertzmann, “A similarity measure for illustration style,” ACM Trans. Graph., 2014, 33, 93:1–93:9.
Gatys, Leon A, Alexander S Ecker, and Matthias Bethge, “A neural algorithm of artistic style,” arXiv preprint arXiv:1508.06576, 2015.
,   , and   , “Image style transfer using convolutional neural networks,” in “Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition” 2016, pp. 2414–2423.
Gebru, Timnit, Jonathan Krause, Yilun Wang, Duyun Chen, Jia Deng, and Li Fei-Fei, “Fine-Grained Car Detection for Visual Census Estimation.,” in “AAAI,” Vol. 2 2017, p. 6.
Horn, Grant Van and Pietro Perona, “The Devil is in the Tails: Fine-grained Classifi- cation in the Wild,” arXiv preprint arXiv:1709.01450, 2017.
Huang, Xinyue and Adriana Kovashka, “Inferring visual persuasion via body language, setting, and deep features,” in “Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops” 2016, pp. 73–79.
Hussain, Zaeem, Mingda Zhang, Xiaozhong Zhang, Keren Ye, Christopher Thomas, Zuha Agha, Nathan Ong, and Adriana Kovashka, “Automatic understanding of image and video advertisements,” in “2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)” IEEE 2017, pp. 1100–1110.
Johnson, Justin, Alexandre Alahi, and Li Fei-Fei, “Perceptual losses for real-time style transfer and super-resolution,” in “European Conference on Computer Vision” Springer 2016, pp. 694–711.
Joo, Jungseock, Francis F Steen, and Song-Chun Zhu, “Automated facial trait judg- ment and election outcome prediction: Social dimensions of face,” in “Proceedings of the IEEE international conference on computer vision” 2015, pp. 3712–3720.
, Weixin Li, Francis F Steen, and Song-Chun Zhu, “Visual persuasion: Inferring communicative intents of images,” in “Proceedings of the IEEE conference on computer vision and pattern recognition” 2014, pp. 216–223.
Karayev, Sergey, Matthew Trentacoste, Helen Han, Aseem Agarwala, Trevor Darrell, Aaron Hertzmann, and Holger Winnemoeller, “Recognizing image style,” arXiv preprint arXiv:1311.3715, 2013.
Karpathy, Andrej and Li Fei-Fei, “Deep visual-semantic alignments for generating image descriptions,” in “Proceedings of the IEEE conference on computer vision and pattern recognition” 2015, pp. 3128–3137.
Kiapour, M Hadi, Kota Yamaguchi, Alexander C Berg, and Tamara L Berg, “Hipster wars: Discovering elements of fashion styles,” in “European conference on computer vision” Springer 2014, pp. 472–488.
Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E Hinton, “ImageNet Classification with Deep Convolutional Neural Networks,” in F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, eds., Advances in Neural Information Processing Systems 25, Curran Associates, Inc., 2012, pp. 1097–1105.
Lee, Yong Jae, Alexei A. Efros, and Martial Hebert, “Style-Aware Mid-level Rep- resentation for Discovering Visual Connections in Space and Time,” in “The IEEE International Conference on Computer Vision (ICCV)” December 2013.
Li, Chuan and Michael Wand, “Combining markov random fields and convolutional neu- ral networks for image synthesis,” in “Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition” 2016, pp. 2479–2486.
Liu, Gaowen, Yan Yan, Elisa Ricci, Yi Yang, Yahong Han, Stefan Winkler, and Nicu Sebe, “Inferring Painting Style with Multi-Task Dictionary Learning.,” in “IJCAI” 2015, pp. 2162–2168.
Liu, Jiongxin, Angjoo Kanazawa, David Jacobs, and Peter Belhumeur, “Dog breed classification using part localization,” in “European Conference on Computer Vision” Springer 2012, pp. 172–185.
Liu, Liu and Dina Mayzlin, “Visual Listening in: Extracting Brand Image Portrayed on Social Media,” 2018.
Liu, Si, Zheng Song, Guangcan Liu, Changsheng Xu, Hanqing Lu, and Shuicheng Yan, “Street-to-shop: Cross-scenario clothing retrieval via parts alignment and auxil- iary set,” in “Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Confer- ence on” IEEE 2012, pp. 3330–3337.
Liu, Xiao, Dokyun Lee, and Kannan Srinivasan, “Large Scale Cross Category Analysis of Consumer Review Content on Sales Conversion Leveraging Deep Learning,” 2017.
Lu, Shasha, Li Xiao, and Min Ding, “A video-based automated recommender (VAR) system for garments,” Marketing Science, 2016, 35 (3), 484–510.
Luan, Fujun, Sylvain Paris, Eli Shechtman, and Kavita Bala, “Deep Photo Style Transfer,” arXiv preprint arXiv:1703.07511, 2017.
Maji, Subhransu, Esa Rahtu, Juho Kannala, Matthew Blaschko, and An- drea Vedaldi, “Fine-grained visual classification of aircraft,” arXiv preprint arXiv:1306.5151, 2013.
Malik, Nikhil, Param Vir Singh, Dokyun Lee, and Kannan Srinivasan, “When Does Beauty Pay. A Large Scale Image Based Appearance Analysis on Career Transitions,” 2018.
McAuley, Julian, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel, “Image-based recommendations on styles and substitutes,” in “Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval” ACM 2015, pp. 43–52.
McDuff, Daniel, Rana El Kaliouby, Jeffrey F Cohn, and Rosalind W Picard, “Predicting ad liking and purchase intent: Large-scale analysis of facial responses to ads,” IEEE Transactions on Affective Computing, 2015, 6 (3), 223–235.
Mei, Tao, Lusong Li, Xian-Sheng Hua, and Shipeng Li, “ImageSense: Towards contextual image advertising,” ACM Transactions on Multimedia Computing, Commu- nications, and Applications (TOMM), 2012, 8 (1), 6.
Murillo, Ana C, Iljung S Kwak, Lubomir Bourdev, David Kriegman, and Serge Belongie, “Urban tribes: Analyzing group photos from a social perspective,” in “Com- puter Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Computer Society Conference on” IEEE 2012, pp. 28–35.
Papatla, Purushottam, “Face, Body or Both? Effects of Partial and Full Visibility of People in VUGC on Consumer Response,” 2018.
Quercia, Daniele, Neil Keith O’Hare, and Henriette Cramer, “Aesthetic capital: what makes london look beautiful, quiet, and happy?,” in “CSCW” 2014.
Rohrbach, Anna, Marcus Rohrbach, Niket Tandon, and Bernt Schiele, “A dataset for movie description,” in “Proceedings of the IEEE conference on computer vision and pattern recognition” 2015, pp. 3202–3212.
Rohrbach, Marcus, Sikandar Amin, Mykhaylo Andriluka, and Bernt Schiele, “A database for fine grained activity detection of cooking activities,” in “Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on” IEEE 2012, pp. 1194– 1201.
S ́anchez, Juan M, Xavier Binefa, and Jordi Vitria, “Shot partitioning based recogni- tion of tv commercials,” Multimedia Tools and Applications, 2002, 18 (3), 233–247.
Selim, Ahmed, Mohamed Elgharib, and Linda Doyle, “Painting style transfer for head portraits using convolutional neural networks,” ACM Transactions on Graphics (ToG), 2016, 35 (4), 129.
Shi, Zijun (June), Dokyun Lee, Param Vir Singh, and Kannan Srinivasan, “Design of Fashion: Can Brand Value be Separated from Style Value?,” 2018.
Snavely, Noah, Steven M Seitz, and Richard Szeliski, “Photo tourism: exploring photo collections in 3D,” in “ACM transactions on graphics (TOG),” Vol. 25 ACM 2006, pp. 835–846.
,   , and   , “Modeling the world from internet photo collections,” International journal of computer vision, 2008, 80 (2), 189–210.
Tapaswi, Makarand, Yukun Zhu, Rainer Stiefelhagen, Antonio Torralba, Raquel Urtasun, and Sanja Fidler, “Movieqa: Understanding stories in movies through question-answering,” in “Proceedings of the IEEE conference on computer vision and pattern recognition” 2016, pp. 4631–4640.
Thomas, Christopher and Adriana Kovashka, “Seeing behind the camera: Identifying the authorship of a photograph,” in “Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition” 2016, pp. 3494–3502.
Tkachenko, Yegor, Asim Ansari, and Olivier Toubia, “Computer-aided Exploration Of Product Designs in High-dimensional Visual Spaces,” 2018.
Todorov, Alexander, “Modeling Visual Impressions of Faces,” 2018.
Veit, Andreas, Balazs Kovacs, Sean Bell, Julian McAuley, Kavita Bala, and Serge Belongie, “Learning visual clothing style with heterogeneous dyadic co-occurrences,” in “Proceedings of the IEEE International Conference on Computer Vision” 2015, pp. 4642–4650.
Vittayakorn, Sirion, Kota Yamaguchi, Alexander C Berg, and Tamara L Berg, “Runway to realway: Visual analysis of fashion,” in “Applications of Computer Vision (WACV), 2015 IEEE Winter Conference on” IEEE 2015, pp. 951–958.
Wilber, Michael J, Chen Fang, Hailin Jin, Aaron Hertzmann, John Collomosse, and Serge J Belongie, “BAM! The Behance Artistic Media Dataset for Recognition Beyond Photography.,” in “ICCV” 2017, pp. 1211–1220.
Xiao, Jianxiong and Yasutaka Furukawa, “Reconstructing the worlds museums,” In- ternational journal of computer vision, 2014, 110 (3), 243–258.
Xiao, Li and Min Ding, “Just the Faces: Exploring the Effects of Facial Features in Print Advertising,” Marketing Science, 2014, 33, 338–352.
Yadati, Karthik, Harish Katti, and Mohan Kankanhalli, “CAVVA: Computational affective video-in-video advertising,” IEEE Transactions on Multimedia, 2014, 16 (1), 15–23.
Yamaguchi, Kota, M Hadi Kiapour, and Tamara L Berg, “Paper doll parsing: Re- trieving similar styles to parse clothing items,” in “Proceedings of the IEEE interna- tional conference on computer vision” 2013, pp. 3519–3526.
, M Hadi Kiapour, Luis E Ortiz, and Tamara L Berg, “Parsing clothing in fashion photographs,” in “Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on” IEEE 2012, pp. 3570–3577.
Yang, Linjie, Ping Luo, Chen Change Loy, and Xiaoou Tang, “A large-scale car dataset for fine-grained categorization and verification,” in “Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition” 2015, pp. 3973–3981.
Yang, Yi and Deva Ramanan, “Articulated pose estimation with flexible mixtures-of- parts,” in “Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on” IEEE 2011, pp. 1385–1392.
Yoganarasimhan, Hema, “Identifying the presence and cause of fashion cycles in data,” Journal of Marketing Research, 2017, 54 (1), 5–26.
Zhang, Shunyuan, Dokyun Lee, Param Vir Singh, and Kannan Srinivasan, “How Much is an Image Worth? The Impact of Professional versus Amateur Airbnb Property Images on Property Demand,” 2018.
Zhao, Gangqiang, Junsong Yuan, Jiang Xu, and Ying Wu, “Discovering the thematic object in commercial videos,” IEEE MultiMedia, 2011, 18 (3), 56–65.
Zhou, YingHui, Shasha Lu, and Min Ding, “A Face Anonymity-Perceptibility Paradigm and an Application in the Online Dating Industry,” 2016.
Zou, Chuhang, Alex Colburn, Qi Shan, and Derek Hoiem, “LayoutNet: Recon- structing the 3D Room Layout from a Single RGB Image,” in “Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition” 2018, pp. 2051–2059.
