---
layout: post
title: Sanity Checks
date: 2017-07-16
---


1. How is the theoretical framework different from Ely et al?

2. How close is the empirical work to the moment by moment studies of ads etc in marketing: (number of genres common in marketing literature: ~20)

3. What is the justification for studying both emotions which include surprise/suspect and info-theoretic measures of surprise/suspect?  

4. What is the difference between behavioral and cognitive/ emotional info?  (page 12).  Are there better terms for this?

5. I don’t understand the discussion of clause transitivity.  Since the ultimate measure is based on SVM for movies with spoilers based on word count, where are clauses being measured?

6. How many movies of 1088 have spoiler alerts? How many spoilers per movie - I assumeonly 1?


7. Are spoilers for surprise or suspense of both?


8. Other emotions - these measures based on word count only? : uh, recent studies on emotion/psychological language have used both dictionary-based and topic-based approaches (for instance, a series studies at Penn World Well Being Project by Ungar, Sligman, Schwartz, etc.): back then I did not used topic-based approach because of the working paper of Toubia et al., in which supervised LDA was used to extract personality clusters/topics...

9. On page 20 - 94% of all trajectories fail to reject null of martingale (5% sig).    what about 100% of all trajectories?  I also don’t understand why unit of observation is not movie instead of movie-evoked emotion.

10. Section 5.2.2 - not sure I understand the justification for why gripping and other words for surprise/suspense are the best way to identify movies.   Is there some justification for using this?  currently seems ad hoc (even if might be right)

11. I can’t tell whether 53.4% agreement is good or not (page 21): not particularly good I think... but then one approach that might make this look better on paper is to show that the task is intrisically subjective and ambiguous, possibly by asking more mTurkers to rate the level of suspense/surprise given a scene discription...?


12. Page 22 -  can you please explain in a table to me what variables are there in literature that you haven’t looked at-  e.g. screens, awards received by cast in previous movies, etc.

13. Page 26 -  what is the problem being solved and how is it being solved by kernel matching estimator and nearest neighbor?   i.e. why is original analysis not robust enough?

14. Endogeneity - not just because of decision endogeneity but unobservables (omitted variables) being systematically correlated with observables e.g. advertising levels for movies.  The fixes you have won’t cure this.   usually people use rival movie levels or previous time periods’ movie characteristics.

15. Papers marked in bibliog -  can you get me these in dropbox: Done.
